{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "upset-collins",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install openai --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fewer-retreat",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformersNote: you may need to restart the kernel to use updated packages.\n",
      "  Downloading sentence_transformers-3.0.0-py3-none-any.whl (224 kB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\damian\\.conda\\envs\\datascience\\lib\\site-packages (from sentence-transformers) (4.58.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\damian\\.conda\\envs\\datascience\\lib\\site-packages (from sentence-transformers) (1.1.2)\n",
      "Collecting transformers<5.0.0,>=4.34.0\n",
      "  Downloading transformers-4.41.2-py3-none-any.whl (9.1 MB)\n",
      "Collecting huggingface-hub>=0.15.1\n",
      "  Downloading huggingface_hub-0.23.2-py3-none-any.whl (401 kB)\n",
      "Requirement already satisfied: Pillow in c:\\users\\damian\\.conda\\envs\\datascience\\lib\\site-packages (from sentence-transformers) (8.1.0)\n",
      "Collecting torch>=1.11.0\n",
      "  Downloading torch-2.3.0-cp38-cp38-win_amd64.whl (159.8 MB)\n",
      "Requirement already satisfied: scipy in c:\\users\\damian\\.conda\\envs\\datascience\\lib\\site-packages (from sentence-transformers) (1.6.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\damian\\.conda\\envs\\datascience\\lib\\site-packages (from sentence-transformers) (1.22.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\damian\\.conda\\envs\\datascience\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (23.2)\n",
      "Collecting filelock\n",
      "  Downloading filelock-3.14.0-py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\damian\\.conda\\envs\\datascience\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (5.4.1)\n",
      "Requirement already satisfied: requests in c:\\users\\damian\\.conda\\envs\\datascience\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.32.2)\n",
      "\n",
      "Collecting fsspec>=2023.5.0\n",
      "  Downloading fsspec-2024.5.0-py3-none-any.whl (316 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\damian\\.conda\\envs\\datascience\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.12.0)\n",
      "Collecting networkx\n",
      "  Downloading networkx-3.1-py3-none-any.whl (2.1 MB)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\damian\\.conda\\envs\\datascience\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (2.11.2)\n",
      "Collecting mkl<=2021.4.0,>=2021.1.1\n",
      "  Downloading mkl-2021.4.0-py2.py3-none-win_amd64.whl (228.5 MB)\n",
      "Collecting sympy\n",
      "  Downloading sympy-1.12.1-py3-none-any.whl (5.7 MB)\n",
      "Collecting intel-openmp==2021.*\n",
      "  Downloading intel_openmp-2021.4.0-py2.py3-none-win_amd64.whl (3.5 MB)\n",
      "Collecting tbb==2021.*\n",
      "  Downloading tbb-2021.12.0-py3-none-win_amd64.whl (286 kB)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\damian\\.conda\\envs\\datascience\\lib\\site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (2024.5.15)\n",
      "Collecting tokenizers<0.20,>=0.19\n",
      "  Downloading tokenizers-0.19.1-cp38-none-win_amd64.whl (2.2 MB)\n",
      "Collecting safetensors>=0.4.1\n",
      "  Downloading safetensors-0.4.3-cp38-none-win_amd64.whl (286 kB)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\damian\\.conda\\envs\\datascience\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (1.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\damian\\.conda\\envs\\datascience\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2020.12.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\damian\\.conda\\envs\\datascience\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\damian\\.conda\\envs\\datascience\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\damian\\.conda\\envs\\datascience\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2.2.1)\n",
      "Requirement already satisfied: joblib>=1.0.0 in c:\\users\\damian\\.conda\\envs\\datascience\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.0.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\damian\\.conda\\envs\\datascience\\lib\\site-packages (from scikit-learn->sentence-transformers) (2.1.0)\n",
      "Collecting mpmath<1.4.0,>=1.1.0\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Installing collected packages: fsspec, filelock, tbb, mpmath, intel-openmp, huggingface-hub, tokenizers, sympy, safetensors, networkx, mkl, transformers, torch, sentence-transformers\n",
      "Successfully installed filelock-3.14.0 fsspec-2024.5.0 huggingface-hub-0.23.2 intel-openmp-2021.4.0 mkl-2021.4.0 mpmath-1.3.0 networkx-3.1 safetensors-0.4.3 sentence-transformers-3.0.0 sympy-1.12.1 tbb-2021.12.0 tokenizers-0.19.1 torch-2.3.0 transformers-4.41.2\n"
     ]
    }
   ],
   "source": [
    "pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "overhead-twenty",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  WHERE DOES DAMIAN WORK?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new GraphCypherQAChain chain...\u001b[0m\n",
      "Generated Cypher:\n",
      "\u001b[32;1m\u001b[1;3mMATCH (p:Person {name: \"Damian\"})-[:WORKED_AT]->(j:Job)\n",
      "RETURN j.company\u001b[0m\n",
      "Full Context:\n",
      "\u001b[32;1m\u001b[1;3m[{'j.company': 'Renault S.A.'}, {'j.company': 'CLK Systems'}, {'j.company': 'DeS S.R.L.'}, {'j.company': 'Fullprism 3D'}]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  WHICH ARE THE STUDIES OF DAMIAN ?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new GraphCypherQAChain chain...\u001b[0m\n",
      "Generated Cypher:\n",
      "\u001b[32;1m\u001b[1;3mMATCH (p:Person {name: \"Damian\"})-[:STUDIED_AT]->(e:Education)\n",
      "RETURN e.institution, e.degree, e.start_date, e.end_date\u001b[0m\n",
      "Full Context:\n",
      "\u001b[32;1m\u001b[1;3m[{'e.institution': 'UNC - Universidad Nacional de Cordoba', 'e.degree': 'Electronics Engineering', 'e.start_date': '01-03-2010', 'e.end_date': '01-12-2015'}, {'e.institution': 'UNC - Universidad Nacional de Cordoba', 'e.degree': 'MBA', 'e.start_date': '01-03-2019', 'e.end_date': '01-09-2021'}, {'e.institution': 'TSP - Telecom Sud Paris', 'e.degree': 'Msc Communications & network services', 'e.start_date': '01-06-2014', 'e.end_date': '01-03-2015'}, {'e.institution': 'Acamica', 'e.degree': 'Data science education program', 'e.start_date': '01-09-2020', 'e.end_date': '01-03-2021'}]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-53-0792f0e70209>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m     \u001b[0mquestion\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"> \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     82\u001b[0m     \u001b[0mcypher_chain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"query\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mquestion\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\datascience\\lib\\site-packages\\ipykernel\\kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m    858\u001b[0m                 \u001b[1;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    859\u001b[0m             )\n\u001b[1;32m--> 860\u001b[1;33m         return self._input_request(str(prompt),\n\u001b[0m\u001b[0;32m    861\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    862\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\datascience\\lib\\site-packages\\ipykernel\\kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m    902\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    903\u001b[0m                 \u001b[1;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 904\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Interrupted by user\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    905\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    906\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Invalid Message:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_community.vectorstores.neo4j_vector import Neo4jVector\n",
    "from langchain_community.graphs import Neo4jGraph\n",
    "from langchain.chains import GraphCypherQAChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "OPENAI_API_KEY = \"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\"\n",
    "\n",
    "chat_llm = ChatOpenAI(openai_api_key=OPENAI_API_KEY)\n",
    "\n",
    "embedding_provider = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)\n",
    "\n",
    "graph = Neo4jGraph(\n",
    "    url=\"neo4j://localhost:7687\",\n",
    "    username=\"neo4j\",\n",
    "    password=\"password\",\n",
    ")\n",
    "\n",
    "movie_plot_vector = Neo4jVector.from_existing_index(\n",
    "    embedding_provider,\n",
    "    url=\"neo4j://localhost:7687\",\n",
    "    username=\"neo4j\",\n",
    "    password=\"password\",\n",
    "    index_name=\"moviePlots\",\n",
    "    embedding_node_property=\"embedding\",\n",
    "    text_node_property=\"country\",\n",
    ")\n",
    "\n",
    "CYPHER_GENERATION_TEMPLATE = \"\"\"\n",
    "You are a Human Resources specialist utilizing a Neo4j database to answer queries about job applicants.\n",
    "Translate the user's question into Cypher based on the provided schema.\n",
    "\n",
    "Instructions:\n",
    "- Use only the provided relationship types and properties in the schema.\n",
    "- Do not use any other relationship types or properties that are not provided.\n",
    "- Construct accurate Cypher queries to retrieve information about an applicant's nationality, job history, education, and age.\n",
    "- If no data is returned, do not attempt to answer the question.\n",
    "- Only respond to questions that require you to construct a Cypher statement.\n",
    "- Do not include any explanations or apologies in your responses.\n",
    "\n",
    "Examples:\n",
    "\n",
    "Find the nationality of an applicant:\n",
    "MATCH (p:Person)-[:HAS_NATIONALITY]->(n:Nationality)\n",
    "WHERE p.name = $applicant_name\n",
    "RETURN n.country\n",
    "\n",
    "Find the job history of an applicant:\n",
    "MATCH (p:Person)-[:WORKED_AT]->(j:Job)\n",
    "WHERE p.name = $applicant_name\n",
    "RETURN j.company, j.position, j.start_date, j.end_date\n",
    "\n",
    "Find the education history of an applicant:\n",
    "MATCH (p:Person)-[:STUDIED_AT]->(e:Education)\n",
    "WHERE p.name = $applicant_name\n",
    "RETURN e.institution, e.degree, e.start_date, e.end_date\n",
    "\n",
    "Find the age of an applicant:\n",
    "MATCH (p:Person)\n",
    "WHERE p.name = $applicant_name\n",
    "RETURN p.age\n",
    "\n",
    "Schema: {schema}\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "cypher_generation_prompt = PromptTemplate(\n",
    "    template=CYPHER_GENERATION_TEMPLATE,\n",
    "    input_variables=[\"schema\", \"question\"],\n",
    ")\n",
    "\n",
    "cypher_chain = GraphCypherQAChain.from_llm(\n",
    "    chat_llm,\n",
    "    graph=graph,\n",
    "    cypher_prompt=cypher_generation_prompt,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "while True:\n",
    "    question = input(\"> \")\n",
    "    cypher_chain.invoke({\"query\": question})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
